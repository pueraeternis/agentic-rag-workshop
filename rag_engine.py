import os
from llama_index.core import (
    VectorStoreIndex, 
    SimpleDirectoryReader, 
    StorageContext, 
    load_index_from_storage,
    Settings
)
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.ollama import OllamaEmbedding
from llama_index.core.node_parser import JSONNodeParser

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
PERSIST_DIR = "./index_store"
DATA_DIR = "./data"

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–µ–π (Ollama)
# –ú—ã –∑–∞–¥–∞–µ–º –∏—Ö –≥–ª–æ–±–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ Settings, —á—Ç–æ–±—ã LlamaIndex –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∏—Ö –≤–µ–∑–¥–µ
print("‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π Ollama...")

# –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å (Qwen3 8B)
Settings.llm = Ollama(
    model="qwen3", 
    base_url="http://localhost:11434",
    request_timeout=300.0, # –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –¥—É–º–∞—Ç—å –¥–æ–ª–≥–æ
    temperature=0          # –î–ª—è RAG –Ω—É–∂–Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å, –∞ –Ω–µ –∫—Ä–µ–∞—Ç–∏–≤
)

# –≠–º–±–µ–¥–¥–∏–Ω–≥ –º–æ–¥–µ–ª—å (Nomic)
Settings.embed_model = OllamaEmbedding(
    model_name="nomic-embed-text",
    base_url="http://localhost:11434"
)

def get_index():
    """
    –°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å.
    Pattern: Checkpointer (–ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ü–∏—è)
    """
    if not os.path.exists(PERSIST_DIR):
        print(f"üìÇ –ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {PERSIST_DIR}. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π...")
        
        # –ß–∏—Ç–∞–µ–º JSON (LlamaIndex —É–º–Ω—ã–π, –æ–Ω —Å–∞–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É)
        documents = SimpleDirectoryReader(DATA_DIR).load_data()
        print(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}")
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å (–¢—É—Ç –∏–¥–µ—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ nomic-embed-text)
        index = VectorStoreIndex.from_documents(documents)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ –¥–∏—Å–∫
        index.storage_context.persist(persist_dir=PERSIST_DIR)
        print("üíæ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
    else:
        print(f"üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å –∏–∑ {PERSIST_DIR}...")
        storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)
        index = load_index_from_storage(storage_context)
        
    return index

def get_rag_tool_function():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –ø–æ–∏—Å–∫–∞, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ —Å–∫–æ—Ä–º–∏—Ç—å –ê–≥–µ–Ω—Ç—É.
    """
    index = get_index()
    # –°–æ–∑–¥–∞–µ–º –¥–≤–∏–∂–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ (top_k=3 - –±–µ—Ä–µ–º 3 —Å–∞–º—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö –∫—É—Å–∫–∞)
    query_engine = index.as_query_engine(similarity_top_k=3)
    
    def search_knowledge_base(query: str) -> str:
        """–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏."""
        response = query_engine.query(query)
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ + –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
        return str(response)
    
    return search_knowledge_base

# –ë–ª–æ–∫ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞ (–µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é)
if __name__ == "__main__":
    tool = get_rag_tool_function()
    print("\n--- –¢–ï–°–¢ –ü–û–ò–°–ö–ê ---")
    res = tool("–ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫—É 429?")
    print(res)